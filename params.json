{
  "name": "CrawlerPack",
  "tagline": "Java 網路資料爬蟲包",
  "body": "# Java 網路資料爬蟲包\r\n[![Maven Central](https://maven-badges.herokuapp.com/maven-central/com.github.abola/crawler/badge.svg)](https://maven-badges.herokuapp.com/maven-central/com.github.abola/crawler)\r\n[![Travis-ci build status](https://travis-ci.org/abola/CrawlerPack.svg)](https://travis-ci.org/abola/CrawlerPack)\r\n\r\n本套件為網路上常見的資料協定、格式，提供了簡易且方便(easy-to-use)的操作接口。套件主要以Jsoup為核心擴展，整合Apache Commons-VFS後，提供更多種協定的操作，也可支援壓縮格式處理。\r\n\r\nRequires JDK 1.7 or higher\r\n\r\nTo add a dependency on CrawlerPack using Maven, use the following:\r\n```xml\r\n<dependency>\r\n    <groupId>com.github.abola</groupId>\r\n    <artifactId>crawler</artifactId>\r\n    <version>1.0.3</version>\r\n</dependency>\r\n```\r\nTo add a dependency using Gradle:\r\n```gradle\r\ndependencies {\r\n    compile 'com.github.abola:crawler:1.0.3'\r\n}\r\n```\r\n\r\nAnd easy-to-use example\r\n```java\r\n// URI format source\r\nString uri = \"https://raw.githubusercontent.com/abola/CrawlerPack/master/test.json\";\r\n    \r\nCrawlerPack.start()\r\n    .getFromJson(uri)\r\n    .select(\"results name\").text() ;\r\n```\r\n\r\n## 爬蟲包特色\r\n### 支援常見網路協定\r\n使用 Apache Commons-VFS 所支援所有協定，常見網路協定如http/https,samba(cifs),ftp,sftp等…詳細列表請參考 https://commons.apache.org/proper/commons-vfs/filesystems.html\r\n\r\n### 支援常見資料格式\r\n* JSON\r\n* XML\r\n* HTML \r\n\r\n### 支援 中文XML標籤 / 中文JSON欄位\r\n爬蟲包套件可正常的處理使用中文命名的XML或JSON\r\n\r\nXML\r\n```xml\r\n<集合>\r\n    <元素>元素名稱1</元素>\r\n    <元素>元素名稱2</元素>\r\n</集合>\r\n```\r\n\r\nJSON\r\n```json\r\n{\"集合\":[\r\n    {\"元素\":\"元素名稱1\"}\r\n    , {\"元素\":\"元素名稱2\"}\r\n]}\r\n```\r\n### 自動偵測遠端資料編碼\r\n爬蟲包建議使用 UTF-8 操作資料。針對非 UTF-8 編碼的遠端資料，爬蟲包預設會啟動自動偵測編碼，並將其轉換為 UTF-8 編碼。\r\n\r\n注意，預設啟用的自動編碼，效能會明顯的不如直接指定編碼，平均測試較直接指定編碼的目標多出300ms以上耗費時間。如果遠端資料非 UTF-8 編碼，大量資料擷取時，直接指定遠端編碼，可有效減少你作業整體耗時。\r\n\r\n```java\r\n// TWSE 2015'三大法人買賣金額統計表\r\nString uri = \"http://www.twse.com.tw/ch/trading/fund/BFI82U/BFI82U_print.php\"\r\n            +\"?begin_date=20150101&end_date=20151231&report_type=month\";\r\n\r\nCrawlerPack.start()\r\n    .setRemoteEncoding(\"big5\")  // 直接指定遠端編碼\r\n    .getFromHtml(uri)\r\n    .select(\"table.board_trad > tbody > tr:nth-child(7) > td:nth-child(4)\").text()\r\n```\r\n\r\n## 一般使用範例\r\n\r\n#### JSON format example\r\n```java\r\n// 即時PM2.5資料\r\nString url = \"http://opendata2.epa.gov.tw/AQX.json\";\r\n\r\nCrawlerPack.start()\r\n    .getFromJson(url)\r\n    .getElementsByTag(\"pm2.5\").text();\r\n```\r\n\r\n#### XML format example\r\n```java    \r\n// 104司人力銀行上 10萬月薪以上的工作資料\r\nString url = \"http://www.104.com.tw/i/apis/jobsearch.cfm?order=2&fmt=4&cols=JOB,NAME&slmin=100000&sltp=S&pgsz=20\";\r\n    \r\nCrawlerPack.start()\r\n    .getFromXml(url)\r\n    .select(\"item\").get(0).attr(\"job\") ;\r\n```\r\n#### Html format example\r\n```java\r\n// ptt 笨版最新文章列表\r\nString url = \"https://www.ptt.cc/bbs/StupidClown/index.html\";\r\n\r\nCrawlerPack.start()\r\n    .getFromHtml(url)\r\n    .select(\"div.title > a\").text();\r\n```\r\n\r\n#### Cookie example\r\n```java\r\n// ptt 八掛版創立首篇廢文標題\r\nString url = \"https://www.ptt.cc/bbs/Gossiping/M.1119222611.A.7A9.html\";\r\n\r\nCrawlerPack.start()\r\n    .addCookie(\"over18\",\"1\")  // 必需在 getFromXXX 前設定Cookie\r\n    .getFromHtml(url)\r\n    .select(\"span:containsOwn(標題) + span:eq(1)\").text();\r\n```\r\n\r\n#### Compressed data example\r\n```java\r\n// 北市Youbike資訊\r\nString url = \"gz:https://tcgbusfs.blob.core.windows.net/blobyoubike/YouBikeTP.gz\";\r\n    \r\n// 目前編號0004站借用資訊\r\nCrawlerPack.start()\r\n    .getFromJson(url)\r\n    .select(\"0004\")\r\n    .select(\"sarea, ar, tot, sbi\").text();\r\n```\r\n\r\n#### Tips\r\n爬蟲包的主要目標，是提供簡易入門的操作模式。然而爬蟲包的效能並不理想，主要原因是編碼偵測\r\n，為了降低預設操作難度，使用了 [juniversalchardet](https://code.google.com/archive/p/juniversalchardet/)\r\n自動偵測遠端內容編碼。直接指定遠端編碼可跳過自動偵測，提升一點效能。如果遠端為UTF8編碼\r\n，便不需要再指定。\r\n\r\n\r\n以台灣證交所網站為例，若不指定編碼時，平均約600ms完成\r\n```java\r\n// TWSE 2015'三大法人買賣金額統計表\r\nString uri = \"http://www.twse.com.tw/ch/trading/fund/BFI82U/BFI82U_print.php\"\r\n            +\"?begin_date=20150101&end_date=20151231&report_type=month\";\r\n\r\n# Guava Stopwatch\r\nStopwatch timer = Stopwatch.createStarted();\r\nCrawlerPack.start()\r\n    .getFromHtml(uri);\r\nSystem.out.println( timer.stop().toString() );\r\n// avg 600ms \r\n```\r\n\r\n\r\n指定遠端編碼為big5後，減少了一點時間，減少的時間，會與你的處理器效能有關\r\n```java\r\nStopwatch timer = Stopwatch.createStarted();\r\nCrawlerPack.start()\r\n    .setRemoteEncoding(\"big5\")\r\n    .getFromHtml(uri);\r\nSystem.out.println( timer.stop().toString() );\r\n// avg 480ms \r\n```\r\n\r\n\r\n## Change log\r\n#### 1.0.3\r\n* 修正(跳過) 壓縮格式無法取得字元長度的臭蟲\r\n\r\n#### 1.0.2\r\n* 修正抓取含路徑的打包檔時會出現 NullPointerException 問題\r\n* 修正自動編碼偵測造成資料清空的bug\r\n\r\n#### 1.0.1\r\n* 調整 getFromHtml 改使用 Jsoup 內建 Html parser\r\n* 增加自動編碼偵測功能  (add library juniversalchardet)\r\n* 增加 setRemoteEncoding(String encoding) 設定遠端內文編碼\r\n\r\n#### 1.0.0\r\n* 調整 api 操作界面\r\n* 增加對Cookie的支援\r\n\r\n#### 0.9.2\r\n* 修正解析註解以及 js 中特殊符號的錯誤\r\n* 修正動態網頁資料被cache的問題\r\n\r\n#### 0.9.1\r\n* 增加授權，使用Apache 2.0 公開授權\r\n* 專案已上傳至公開的 Maven Repository 現在可以直接透過pom.xml使用爬蟲包\r\n* 修正 https PKIX 驗證無法通過的問題\r\n\r\n## Reference\r\n* JCConf 2015 TW 高效率資料爬蟲組合包 投影片 http://www.slideshare.net/ssuser438746/jcconf-2015-tw\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}